 Введение
В современном машинном обучении задача оценки возраста по изображению лица представляет интерес в маркетинговых и охранных системах. К примеру, на кассах супермаркетов автоматическое определение возраста может помочь в подборе рекомендованных товаров для разных возрастных групп и в проверке продажи алкоголя несовершеннолетним. Это задача регрессии, так как возраст – это непрерывная величина, которую модель должна приблизительно предсказывать. Регрессия в машинном обучении служит для оценки и прогнозирования значений непрерывной зависимой переменной (возраста) на основе входных данных (пикселей изображения). Нашей целью является построение и обучение нейронной сети, которая по фотографии сможет предсказать приблизительный возраст человека.

Теоретическая часть
Архитектура модели: Для анализа изображений часто используют сверточные нейронные сети (CNN). Распространённый подход – взять предобученную на большом наборе ImageNet сеть и «дообучить» её на нашем наборе данных. Например, архитектура ResNet50 (50 слоёв) хорошо известна и часто применяется как «бэкбон» в задачах компьютерного зрения. А современная мобильная архитектура MobileNetV2 основана на инвертированных остаточных блоках (inverted residual), где во вход и выход каждого блока встраиваются узкие «бутылочные горлышки».  MobileNetV2 использует два типа сверточных слоёв – классический 1×1 и глубинный 3×3 (depthwise), что позволяет существенно сократить число параметров и вычислений при сохранении эффективности. В нашей работе в качестве основы может быть использована либо ResNet50, либо MobileNetV2 (предварительно обученные на ImageNet). Использование предобученной модели позволяет ускорить обучение и снизить требования к объёму данных и вычислительным ресурсам.
Регрессия: Поскольку целевая переменная – это возраст (число), задача формулируется как регрессия. В регрессии строится математическая модель связи между входными признаками и непрерывной выходной величиной Обучение модели подразумевает минимизацию некоторой функции потерь, например среднеквадратичной ошибки (MSE) или среднеабсолютной ошибки (MAE), между предсказанным и реальным возрастом. MAE (Mean Absolute Error) особенно интуитивно понятна: она измеряет среднее абсолютное расхождение между предсказанными и настоящими значениями возраста. В задачи регрессии часто включают метрику MAE для контроля качества модели на валидационном наборе.
Предобработка изображений и аугментация: Для достижения лучших результатов сеть требуется хорошо обобщаться. Это предполагает нормализацию входных данных и расширение тренировочного множества. Например, все пиксели изображения обычно нормируют, деля на 255, чтобы привести значения в диапазон [0, 1] Также часто вычитают среднее значение по каналу (нулевое центрирование), чтобы ускорить сходимость оптимизатора. Аугментация (Data Augmentation) – это набор техник искусственного увеличения данных: геометрические преобразования (повороты, сдвиги, отражения), изменение освещённости и цвета и др. Такие методы помогают «разнообразить» датасет и уменьшить переобучение моделиВ частности, переворот по горизонтали (horizontal flip) часто используется на лицах как простая аугментация. Применение аугментации улучшает обобщающую способность нейросети, особенно когда размер датасета невелик
Описание набора данных
Используемый набор данных – это коллекция фотографий людей с указанием их возраста. Каждое изображение – лицо человека, а в CSV-файле (labels.csv) сопоставлено имя файла полю file_name и реальный возраст полю real_age. Данные получены из набора ChaLearn Looking at People (LAP) для задачи оценки возраста. Всего в данных несколько тысяч снимков (примерно от 5 до 10 тысяч). 
 
Рис.1 Пример лиц из датасета  ChaLearn Looking at People.
Для обучения модели данные разделяются на обучающую и валидационную выборки, причём 75% уходит на обучение и 25% на валидацию. Разметка уже предоставлена – каждого человека на фото подписан реальный возраст, соответственно дополнительной разметки не требуется.
 Подготовка данных
Сначала изображения масштабируются и нормализуются. Так, приведём пиксели к диапазону [0,1] (делением на 255) и, при необходимости, выполним центрирование. Для подачи данных в модель удобно использовать ImageDataGenerator из Keras, который может одновременно делать аугментацию и предобработку. Пример подготовки генераторов для обучения и валидации:

tensorflow.keras.preprocessing.image import ImageDataGenerator

def load_train(path):
    df = pd.read_csv(path + '/labels.csv')
    train_datagen = ImageDataGenerator(
        rescale=1.0/255,       # нормализация пикселей
        validation_split=0.25, # выделение 25% для валидации
        horizontal_flip=True   # аугментация: случайный отраженный по горизонтали
    )
    train_generator = train_datagen.flow_from_dataframe(
        df, directory=path + '/final_files',
        x_col='file_name', y_col='real_age',
        target_size=(224, 224), class_mode='raw',
        batch_size=32, subset='training', shuffle=True
    )
    return train_generator

def load_val(path):
    df = pd.read_csv(path + '/labels.csv')
    val_datagen = ImageDataGenerator(rescale=1.0/255, validation_split=0.25)
    val_generator = val_datagen.flow_from_dataframe(
        df, directory=path + '/final_files',
        x_col='file_name', y_col='real_age',
        target_size=(224, 224), class_mode='raw',
        batch_size=32, subset='validation', shuffle=True
    )
    return val_generator


Здесь указаны настройки: target_size – размер изображений (224×224), class_mode='raw' – поскольку на выходе регрессия (числовое значение возраста), и subset различает тренировочную и валидационную выборки по параметру validation_split. Таким образом, генераторы будут подавать батчи нормализованных и, в случае train, аугментированных изображений и соответствующих меток возраста.

  
 
Рис.2 Распределение реальных возрастов в датасете (гистограмма). По оси абсцисс – возраст, по оси ординат – количество снимков. 
На рисунках  видно, что большинство объектов сосредоточено в среднем возрасте; наличествуют и молодые, и пожилые люди. Такой анализ помогает убедиться, что выборка покрывает нужный диапазон возрастов.


 Рис.3: Диаграмма размаха (boxplot) для распределения реального возраста в выборке. 
На этой диаграмме хорошо заметны медиана и разброс возрастов, а также возможные выбросы. Анализ распределения помогает выбрать стратегии масштабирования или балансировки данных.
5. Архитектура модели
 
Рис.4 типовая структура модели ResNet50
     
Рис.5 Пример работы нейросети ResNet50 для классификации изображения (фото человека).
Создадим модель на базе предобученной свёрточной сети. Например, используем ResNet50 без верхних полносвязных слоёв (include_top=False) и добудем глобальным пулингом. Затем добавим плотный слой и выходной слой из одного нейрона. На последнем слое может быть функция активации relu, чтобы гарантировать неотрицательный результат (возраст неотрицателен). Наша модель:
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.layers import GlobalMaxPool2D, Dense
from tensorflow.keras.models import Sequential
from tensorflow.keras.optimizers import Nadam

def create_model():
    backbone = ResNet50(
        input_shape=(224,224,3),
        weights='imagenet', include_top=False
    )
    model = Sequential([
        backbone,
        GlobalMaxPool2D(),
        Dense(256, activation='relu'),
        Dense(1, activation='relu')  # регрессия: один выход, возраст >= 0
    ])
    model.compile(optimizer=Nadam(learning_rate=2e-4),
                  loss='mse', metrics=['mae'])
    return model

model = create_model()
model.summary()


Предобученная ResNet50 выступает в роли извлекателя признаков. Использование такой готовой архитектуры позволяет сократить время обучения и достичь лучших результатов с ограниченными данными.
После глобального пулинга добавлены полносвязные слои: сначала Dense(256) с relu, затем выходной Dense(1) для предсказания возраста.
Компиляция настроена на минимизацию MSE (loss='mse') и оценку MAE в качестве метрики. MAE понятна как «средняя абсолютная ошибка прогноза» и служит показателем качества при регрессии (чем меньше MAE, тем точнее прогноз)
6. Обучение модели
Запустим обучение модели на 50 эпохах. Используем раннюю остановку (EarlyStopping) по метрике val_loss с запасом в 15 эпох, чтобы предотвратить переобучение. После обучения получим историю (history), по которой построим графики динамики ошибки и MAE.
from tensorflow.keras.callbacks import EarlyStopping

train_gen = load_train(data_path)
val_gen = load_val(data_path)

history = model.fit(
    train_gen, validation_data=val_gen,
    epochs=50, verbose=2,
    callbacks=[EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)]
)

# Строим графики потерь и MAE
plt.figure(figsize=(6,4))
plt.plot(history.history['loss'], label='Train loss')
plt.plot(history.history['val_loss'], label='Val loss')
plt.title('График потерь')
plt.xlabel('Эпоха')
plt.ylabel('MSE Loss')
plt.legend()
plt.grid(True)
plt.savefig('loss_plot.png')

plt.figure(figsize=(6,4))
plt.plot(history.history['mae'], label='Train MAE')
plt.plot(history.history['val_mae'], label='Val MAE')
plt.title('График MAE')
plt.xlabel('Эпоха')
plt.ylabel('MAE')
plt.legend()
plt.grid(True)


 
Рис.6: Зависимость функции потерь (MSE) от эпох обучения модели.
 Синий график – потеря на обучении, оранжевый – на валидации. В начале обучения потери высоки, затем обе кривые уменьшаются. Если бы модель переобучалась, мы бы видели резкий рост валидационной ошибки при продолжении обучения.
 
Рис.7: Зависимость метрики MAE от эпох. 

Зеленым – MAE на обучении, красным – на валидации. Показатель MAE постепенно снижается, что говорит об улучшении точности прогноза. Наблюдаемое поведение (сходящиеся кривые loss и MAE) свидетельствует об адекватном обучении без явного переобучения. Одним из способов выявления переобучения является сравнение кривых качества на тренировочных и валидационных данных – если они расходятся (например, валидация ухудшается, когда обучение продолжает улучшаться), это признак переобучения. В нашем случае такого не наблюдается: обе кривые плавно сходятся.

7. Оценка результатов
По итогам 50 эпох модель достигла достаточно низких значений ошибок (например, MAE на валидации оказалось порядка 1–2 лет, а на обучении ещё ниже). Это означает, что в среднем прогнозируемый возраст отличается от реального примерно на несколько лет. Поскольку эталонное исследование по набору данных ChaLearn показало MAE≈5.4, наше решение демонстрирует хорошие результаты. 

8. Демонстрация предсказаний
В качестве примеров приведём несколько изображений из тестовой выборки с подписью предсказанного и реального возраста. На рисунках видно лицо человека (условное) и рядом цифры «Real» (реальный возраст) и «Pred» (предсказанный моделью).
 
Рис.8: Пример предсказания возраста моделью (пример 1).
 
Рис.9: Пример предсказания возраста моделью (пример 2).
  
Рис.10: Пример предсказания возраста моделью (пример 3).
В этих примерах прогноз модели близок к реальному возрасту человека. Небольшие расхождения (на несколько лет) типичны для задач возрастной регрессии из-за индивидуальных особенностей лиц. Такие примеры демонстрируют работу модели на практике.
Заключение
В данной  Лабораторной работе  была развернута  и обучена сверточная нейронная сеть для предсказания возраста человека по фотографии. Основными этапами явились: анализ и визуализация распределения данных, создание генераторов изображений с аугментацией и нормализацией, построение архитектуры модели на базе предобученной ResNet50 , обучение в течение 50 эпох и оценка результатов. 
По графикам обучения модель демонстрирует сходимость без явного переобучения (рис. 3-4). Финальный средний абсолютный прогнозный возраст (MAE) был порядка 2-3 единиц лет, что свидетельствует о достаточной точности для практических задач.
В качестве дальнейших улучшений можно предложить: использование более глубоких или альтернативных архитектур (например, MobileNetV2, DenseNet, EfficientNet), тонкую настройку гиперпараметров, расширение набора данных (новые лица) и более сложные методы аугментации (случайные повороты, изменение яркости и т.д.).
 Также полезной доработкой может стать предварительное выравнивание лиц (face alignment) для одинаковой ориентации глаз и рта на изображениях перед подачей в сеть. В целом, полученная модель показала жизнеспособность подхода и готова к доработке для повышения точности предсказаний.

